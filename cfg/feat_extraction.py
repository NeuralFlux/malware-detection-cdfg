"""
This module processes the NetworkX graphs and their execution traces
to extract custom features for learning
"""

from queue import Queue

from nltk import ngrams

import os

import pandas as pd


class FeatureExtractor(object):
    """
    This class manages the core functionality of the module
    Can extract:
      - ngrams of execution traces
      - {extendable}
    """

    def __init__(self, func_graph_dict: dict, n_gram: int = 3) -> None:
        """
        Collect the execution traces and parameters for further
        processing
        """
        self.func_graph_dict = func_graph_dict
        self.N = n_gram
        assert n_gram > 1  # enforce at least bigram

        self.build_ngrams()
    
    def encode_ngrams(self) -> None:

        for idx, n_tuple in enumerate(self.all_ngrams):
            ngram_id = 0
            for pos in range(self.N):
                # NOTE 1311 = total number of opcodes
                ngram_id += n_tuple[pos].opcode * (1311 ** pos)
            self.all_ngrams[idx] = ngram_id
    
    def filter_ngrams(self, ngrams):
        filt_ngrams = []

        # remove ngrams that contain undefined instructions
        for ngram in ngrams:
            for inst in ngram:
                if inst.opcode == -1:
                    break
            else:  # NOTE for-else construct
                filt_ngrams.append(ngram)
        
        return filt_ngrams

    def build_ngrams(self) -> None:
        """
        Generate ngrams from execution traces of graphs
        """

        self.all_ngrams = []

        for _, v in self.func_graph_dict.items():
            ngram_list = []  # one list for all traces of one graph
            for ex_path in v[1]:
                # buffer of instructions rather than loading all
                # eases memory usage
                inst_buffer = []

                idx = 0
                while idx < len(ex_path):
                    # add instructions from nodes such that they are
                    # at least N in number
                    while len(inst_buffer) < self.N:
                        node = ex_path[idx]
                        inst_buffer.extend(v[0].nodes[node]['insts'])
                        idx += 1
                    
                    # build ngrams over the instruction buffer
                    unfiltered_ngrams = ngrams(inst_buffer, self.N)
                    ngram_list.extend(
                        self.filter_ngrams(unfiltered_ngrams)
                    )

                    # preserve last (N-1) instructions as their ngrams
                    # with upcoming instructions are pending
                    inst_buffer = inst_buffer[:][-(self.N - 1):]

            self.all_ngrams.extend(ngram_list)

        # encode all the ngrams into unique numbers
        # for easier processing
        self.encode_ngrams()

    def export_features(self,
                        curr_file: str,
                        is_malware: bool = False,
                        feat_csv_name: str = "all_features.csv"):

        if os.path.exists(feat_csv_name):
            # append
            df = pd.DataFrame({
                'file_name': [curr_file],
                'ngrams': [' '.join(map(str, self.all_ngrams))],
                'class': [int(is_malware)]  # 1 for malware
            })

            df.to_csv(feat_csv_name, index=False, header=False, mode='a')
        else:
            # create
            df = pd.DataFrame({
                'file_name': [curr_file],
                'ngrams': [' '.join(map(str, self.all_ngrams))],
                'class': [int(is_malware)]  # 1 for malware
            })

            df.to_csv(feat_csv_name, index=False)
