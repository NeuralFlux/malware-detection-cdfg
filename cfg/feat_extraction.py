"""
This module processes the NetworkX graphs and their execution traces
to extract custom features for learning
"""

import os

import pandas as pd

from instructions import NGram


class FeatureExtractor(object):
    """
    This class manages the core functionality of the module
    Can extract:
      - ngrams of execution traces
      - {extendable}
    """

    def __init__(self, func_graph_dict: dict, n_gram: int = 3) -> None:
        """
        Collect the execution traces and parameters for further
        processing
        """
        self.func_graph_dict = func_graph_dict
        self.n = n_gram
        assert n_gram > 1  # enforce at least bigram

        self.compile_ngrams()

    def compile_ngrams(self) -> None:
        """
        Generate ngrams from execution traces of graphs
        """

        self.all_ngrams = []

        for _, v in self.func_graph_dict.items():
            graph_ngram_list = []  # one list for all traces of one graph
            for ex_path in v[1]:
                # buffer of instructions rather than loading all
                # eases memory usage
                inst_buffer = []

                idx = 0
                while idx < len(ex_path):
                    # add instructions from nodes such that they are
                    # at least N in number
                    while len(inst_buffer) < self.n and idx < len(ex_path):
                        node = ex_path[idx]
                        inst_buffer.extend(v[0].nodes[node]['insts'])
                        idx += 1

                    # build ngrams over the instruction buffer
                    graph_ngram_list.extend(
                        build_valid_ngrams(inst_buffer)
                    )

                    # preserve last (N-1) instructions as their ngrams
                    # with upcoming instructions are pending
                    inst_buffer = inst_buffer[:][-(self.n - 1):]

            self.all_ngrams.extend(graph_ngram_list)

    def export_features(self,
                        curr_file: str,
                        is_malware: bool = False,
                        feat_csv_name: str = "all_features.csv"):

        if os.path.exists(feat_csv_name):
            # append
            df = pd.DataFrame({
                'file_name': [curr_file],
                'ngrams': [' '.join(map(str, self.all_ngrams))],
                'class': [int(is_malware)]  # 1 for malware
            })

            df.to_csv(feat_csv_name, index=False, header=False, mode='a')
        else:
            # create
            df = pd.DataFrame({
                'file_name': [curr_file],
                'ngrams': [' '.join(map(str, self.all_ngrams))],
                'class': [int(is_malware)]  # 1 for malware
            })

            df.to_csv(feat_csv_name, index=False)


# TODO generalise function for ngram (currently only tri-grams)
def build_valid_ngrams(inst_buffer):
    ngrams_buffer = []

    for idx in range(len(inst_buffer) - 2):
        temp_ngram = NGram([
            inst_buffer[idx],
            inst_buffer[idx + 1],
            inst_buffer[idx + 2]
        ][:])  # NOTE Copy the buffer to avoid overwriting

        if not temp_ngram.invalid_flag:
            ngrams_buffer.append(temp_ngram)

    return ngrams_buffer
